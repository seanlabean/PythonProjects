{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voronoi Mesh\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.Voronoi.html\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.voronoi_plot_2d.html\n",
    "\n",
    "Simple plotting of center points of mesh data, using scipy to construct the corresponding Voronoi mesh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def voronoi_volumes(points):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/19634993/volume-of-voronoi-cell-python\n",
    "    \"\"\"\n",
    "    v = Voronoi(points)\n",
    "    vol = np.zeros(v.npoints)\n",
    "    for i, reg_num in enumerate(v.point_region):\n",
    "        indices = v.regions[reg_num]\n",
    "        if -1 in indices: # some regions can be opened\n",
    "            vol[i] = np.inf\n",
    "        else:\n",
    "            vol[i] = ConvexHull(v.vertices[indices]).volume\n",
    "            print ConvexHull(v.vertices[indices]).equations\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "font = {'family' : 'sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "points = np.array([[0.0,0.0], [0, 1.5], [-0.01, -0.99], [-2.49, 0.25], [-0.25, 1.0], [1.9, -1.0]])\n",
    "from scipy.spatial import Voronoi, ConvexHull, voronoi_plot_2d\n",
    "vor = Voronoi(points)\n",
    "print \"vertices: \\npositions of all voronoi cell vertices (order corresponds to vertex ID)\\n\", vor.vertices\n",
    "print \"regions: \\nindices of voronoi vertices for each voronoi cell\\n\", vor.regions\n",
    "print \"points: \\nvoronoi cell centers\\n\", vor.points\n",
    "#print \"ridge verticies\\n\", vor.ridge_vertices\n",
    "#print \"ridge points\\n\", vor.ridge_points\n",
    "print \"point region: \\nindex of vor.region corresponding to vor.points\\n\", vor.point_region\n",
    "volume = voronoi_volumes(points)\n",
    "print \"voulme: \\nsame order as vor.points\\n\", volume\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('xkcd:dark red')\n",
    "fig = voronoi_plot_2d(vor,ax,show_vertices=False,line_colors='white',line_width=2, line_alpha=0.9, point_size=15)\n",
    "plt.gca().add_patch(Rectangle((-1.5,0.5),1.7,1.7,\n",
    "                    edgecolor='red',\n",
    "                    facecolor='none',\n",
    "                    lw=4))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.xlim(-2.8,2.8)\n",
    "plt.ylim(-2.8,2.8)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3d Voronoi Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([[0, 1.5, 1.0], [-0.01, -0.99, -1.0], [-2.49, 0.25, 1.0], [-0.25, 1.0, -1.0]])\n",
    "vor = Voronoi(points)\n",
    "vor.vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate mesh from points from AREPO hdf5\n",
    "\n",
    "I want to read in mesh points from an AREPO output file to reconstruct the voronoi mesh in python in a KDTree. This way, I can query each cell in a FLASH grid and fill it with the appropriate intrinsic field values (density, temperature, pressure) for whichever mesh the cell center falls in.\n",
    "\n",
    "scipy.interpolate.NearestNDInterpolator\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.NearestNDInterpolator.html\n",
    "* https://github.com/scipy/scipy/blob/v1.7.1/scipy/interpolate/ndgriddata.py#L20-L111\n",
    "\n",
    "Steps:\n",
    "1. Read in AREPO snapshot (~9 million points)\n",
    "2. Use scipy NearestNDInterpolator to construct mesh and get a field value for 512 grid points (mimicking a FLASH block). Un-modified, NearestNDInterpolator will regenerate the mesh from scratch for each point.\n",
    "3. Time this process. If it takes longer than 1/1000th of a day (1.5 minutes), then we need to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import NearestNDInterpolator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import h5py\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_kdtree(data_coords, field_set):\n",
    "    nearest_interp = NearestNDInterpolator(list(zip(data_coords[0], data_coords[1], data_coords[2])), field_set)\n",
    "    return nearest_interp\n",
    "def interp_data_new(interp, cell_coords):\n",
    "    interp_result = interp(cell_coords[0], cell_coords[1], cell_coords[2])\n",
    "    return interp_result\n",
    "def gen_cell_coords(x,y,z):\n",
    "    cellX = np.linspace(min(x), max(x), num=512)*np.random.random()\n",
    "    cellY = np.linspace(min(y), max(y), num=512)*np.random.random()\n",
    "    cellZ = np.linspace(min(z), max(z), num=512)*np.random.random()\n",
    "    cell_coords = [cellX,cellY,cellZ]\n",
    "    return cell_coords\n",
    "def interp_data(data_coords, cell_coords, field_set):\n",
    "    \"\"\"\n",
    "    Generates Nearest Neighbor object with given field values assigned to input data coords.\n",
    "    For a set of sample data points, return interpolated field values.\n",
    "    \n",
    "    Inputs:\n",
    "    data_coords - coordinates of AREPO mesh cells\n",
    "    cell_coords - coordinates of FLASH cell centers\n",
    "    field_set   - AREPO field data\n",
    "    \n",
    "    Output:\n",
    "    interp_result - interpolated data at each FLASH cell center\n",
    "    \"\"\"\n",
    "    interp = NearestNDInterpolator(list(zip(data_coords[0], data_coords[1], data_coords[2])), field_set)\n",
    "    interp_result = interp(cell_coords[0], cell_coords[1], cell_coords[2])\n",
    "    return interp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../../AREPO-TORCH/snapshot_550_9.hdf5','r')\n",
    "coords_set = np.array(f[\"PartType0\"][\"Coordinates\"])\n",
    "x = coords_set[:,0]\n",
    "y = coords_set[:,1]\n",
    "z = coords_set[:,2]\n",
    "points = np.zeros(len(x), dtype=object)\n",
    "for i,point in enumerate(points):\n",
    "    xyz = []\n",
    "    xyz.append(float(x[i]))\n",
    "    xyz.append(float(y[i]))\n",
    "    xyz.append(float(z[i]))\n",
    "    xyz = np.array(xyz)\n",
    "    points[i] = xyz\n",
    "print points[0]\n",
    "vor = Voronoi(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(vor.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "f = h5py.File('../../AREPO-TORCH/snapshot_550_9.hdf5','r')\n",
    "coords_set = np.array(f[\"PartType0\"][\"Coordinates\"])\n",
    "x = coords_set[:,0]\n",
    "y = coords_set[:,1]\n",
    "z = coords_set[:,2]\n",
    "data_coords = [x,y,z]\n",
    "\n",
    "density_set = np.array(f[\"PartType0\"][\"Density\"])\n",
    "velocity_set = np.array(f[\"PartType0\"][\"Velocities\"])\n",
    "velx = velocity_set[:,0]\n",
    "vely = velocity_set[:,1]\n",
    "velz = velocity_set[:,2]\n",
    "time1 = time.time()\n",
    "print(\"file data extracted\", time1-time_start)\n",
    "cell_coords0 = gen_cell_coords(x,y,z)\n",
    "cell_coords1 = gen_cell_coords(x,y,z)\n",
    "cell_coords2 = gen_cell_coords(x,y,z)\n",
    "cell_coords3 = gen_cell_coords(x,y,z)\n",
    "time2 = time.time()\n",
    "print(\"ignore FLASH block generation\", time2-time1)\n",
    "dens_tree = gen_kdtree(data_coords, [density_set, velx])\n",
    "velx_tree = gen_kdtree(data_coords, velx)\n",
    "time3 = time.time()\n",
    "print(\"2 trees generated\", time3-time2)\n",
    "f.close()\n",
    "\n",
    "dens_interp = interp_data_new(dens_tree, cell_coords0)\n",
    "velx_interp = interp_data_new(velx_tree, cell_coords0)\n",
    "time4 = time.time()\n",
    "print(\"block 1 fields interpolated\", time4-time3)\n",
    "dens_interp = interp_data_new(dens_tree, cell_coords1)\n",
    "velx_interp = interp_data_new(velx_tree, cell_coords1)\n",
    "dens_interp = interp_data_new(dens_tree, cell_coords2)\n",
    "velx_interp = interp_data_new(velx_tree, cell_coords2)\n",
    "dens_interp = interp_data_new(dens_tree, cell_coords3)\n",
    "velx_interp = interp_data_new(velx_tree, cell_coords3)\n",
    "\n",
    "time5 = time.time()\n",
    "print(\"blocks 2, 3, 4 interpolated\", time5-time4)\n",
    "print(\"elapsed: \", time5-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "f = h5py.File('../../AREPO-TORCH/snapshot_550_9.hdf5','r')\n",
    "coords_set = np.array(f[\"PartType0\"][\"Coordinates\"])\n",
    "density_set = np.array(f[\"PartType0\"][\"Density\"])\n",
    "velocity_set = np.array(f[\"PartType0\"][\"Velocities\"])\n",
    "#We need to separate velocity vector, need to interpolate each component\n",
    "velx = velocity_set[:,0]\n",
    "vely = velocity_set[:,1]\n",
    "velz = velocity_set[:,2]\n",
    "\n",
    "eAbund_set = np.array(f[\"PartType0\"][\"ElectronAbundance\"])\n",
    "intEner_set = np.array(f[\"PartType0\"][\"InternalEnergy\"])\n",
    "#Calculating temperature and pressure. Have to double and triple check these calcs.\n",
    "temp_set = (7./3 - 1)*(intEner_set/1.83e16)*1.0e10*(4*1.67e-23)/(1+3*0.76 + 4*0.76*eAbund_set)\n",
    "pres_set = (7./3 -1)*density_set*intEner_set\n",
    "\n",
    "# Isolate AREPO mesh x, y, z, and put into list\n",
    "x = coords_set[:,0]\n",
    "y = coords_set[:,1]\n",
    "z = coords_set[:,2]\n",
    "data_coords = [x,y,z]\n",
    "time1 = time.time()\n",
    "print(\"file data extracted\", time1-time_start)\n",
    "# Generate 512 FLASH cell centers (currently just evenly spaced througout comp domain)\n",
    "cellX = np.linspace(min(x), max(x), num=512)\n",
    "cellY = np.linspace(min(y), max(y), num=512)\n",
    "cellZ = np.linspace(min(z), max(z), num=512)\n",
    "cell_coords = [cellX,cellY,cellZ]\n",
    "time2 = time.time()\n",
    "print(\"ignore FLASH block generation\", time2-time1)\n",
    "dens_interp0 = interp_data(data_coords, cell_coords, density_set)\n",
    "#temp_interp = interp_data(data_coords, cell_coords, temp_set)\n",
    "#pres_interp = interp_data(data_coords, cell_coords, pres_set)\n",
    "velx_interp0 = interp_data(data_coords, cell_coords, velx)\n",
    "#vely_interp = interp_data(data_coords, cell_coords, vely)\n",
    "#velz_interp = interp_data(data_coords, cell_coords, velz)\n",
    "f.close()\n",
    "time3 = time.time()\n",
    "print(\"2 trees and interpolation\", time3-time2)\n",
    "print(\"time block 1\", time3-time_start)\n",
    "f = h5py.File('../../AREPO-TORCH/snapshot_550_9.hdf5','r')\n",
    "coords_set = np.array(f[\"PartType0\"][\"Coordinates\"])\n",
    "\n",
    "density_set = np.array(f[\"PartType0\"][\"Density\"])\n",
    "velocity_set = np.array(f[\"PartType0\"][\"Velocities\"])\n",
    "#We need to separate velocity vector, need to interpolate each component\n",
    "velx = velocity_set[:,0]\n",
    "vely = velocity_set[:,1]\n",
    "velz = velocity_set[:,2]\n",
    "x = coords_set[:,0]\n",
    "y = coords_set[:,1]\n",
    "z = coords_set[:,2]\n",
    "data_coords = [x,y,z]\n",
    "\n",
    "time4 = time.time()\n",
    "print(\"file data extracted for second block\", time4-time3)\n",
    "\n",
    "cellX = np.linspace(min(x), max(x), num=512)*0.5\n",
    "cellY = np.linspace(min(y), max(y), num=512)*0.5\n",
    "cellZ = np.linspace(min(z), max(z), num=512)*0.5\n",
    "cell_coords = [cellX,cellY,cellZ]\n",
    "time5 = time.time()\n",
    "print(\"ignore FLASH block generation\", time5-time4)\n",
    "\n",
    "dens_interp1 = interp_data(data_coords, cell_coords, density_set)\n",
    "velx_interp1 = interp_data(data_coords, cell_coords, velx)\n",
    "\n",
    "f.close()\n",
    "time6 = time.time()\n",
    "print(\"2 trees and interpolation\", time6-time5)\n",
    "print(\"time block 2\", time6-time3)\n",
    "f = h5py.File('../../AREPO-TORCH/snapshot_550_9.hdf5','r')\n",
    "coords_set = np.array(f[\"PartType0\"][\"Coordinates\"])\n",
    "\n",
    "density_set = np.array(f[\"PartType0\"][\"Density\"])\n",
    "velocity_set = np.array(f[\"PartType0\"][\"Velocities\"])\n",
    "#We need to separate velocity vector, need to interpolate each component\n",
    "velx = velocity_set[:,0]\n",
    "vely = velocity_set[:,1]\n",
    "velz = velocity_set[:,2]\n",
    "x = coords_set[:,0]\n",
    "y = coords_set[:,1]\n",
    "z = coords_set[:,2]\n",
    "data_coords = [x,y,z]\n",
    "\n",
    "time7 = time.time()\n",
    "print(\"file data extracted for third block\", time7-time6)\n",
    "\n",
    "cellX = np.linspace(min(x), max(x), num=512)*0.5\n",
    "cellY = np.linspace(min(y), max(y), num=512)*0.5\n",
    "cellZ = np.linspace(min(z), max(z), num=512)*0.5\n",
    "cell_coords = [cellX,cellY,cellZ]\n",
    "time8 = time.time()\n",
    "print(\"ignore FLASH block generation\", time8-time7)\n",
    "\n",
    "dens_interp2 = interp_data(data_coords, cell_coords, density_set)\n",
    "velx_interp2 = interp_data(data_coords, cell_coords, velx)\n",
    "\n",
    "f.close()\n",
    "time9 = time.time()\n",
    "print(\"2 trees and interpolation\", time9-time8)\n",
    "print(\"time block 2\", time9-time6)\n",
    "\n",
    "f = h5py.File('../../AREPO-TORCH/snapshot_550_9.hdf5','r')\n",
    "coords_set = np.array(f[\"PartType0\"][\"Coordinates\"])\n",
    "\n",
    "density_set = np.array(f[\"PartType0\"][\"Density\"])\n",
    "velocity_set = np.array(f[\"PartType0\"][\"Velocities\"])\n",
    "#We need to separate velocity vector, need to interpolate each component\n",
    "velx = velocity_set[:,0]\n",
    "vely = velocity_set[:,1]\n",
    "velz = velocity_set[:,2]\n",
    "x = coords_set[:,0]\n",
    "y = coords_set[:,1]\n",
    "z = coords_set[:,2]\n",
    "data_coords = [x,y,z]\n",
    "\n",
    "time10 = time.time()\n",
    "print(\"file data extracted for fourth block\", time10-time9)\n",
    "\n",
    "cellX = np.linspace(min(x), max(x), num=512)*0.5\n",
    "cellY = np.linspace(min(y), max(y), num=512)*0.5\n",
    "cellZ = np.linspace(min(z), max(z), num=512)*0.5\n",
    "cell_coords = [cellX,cellY,cellZ]\n",
    "time11 = time.time()\n",
    "print(\"ignore FLASH block generation\", time11-time10)\n",
    "\n",
    "dens_interp3 = interp_data(data_coords, cell_coords, density_set)\n",
    "velx_interp3 = interp_data(data_coords, cell_coords, velx)\n",
    "\n",
    "f.close()\n",
    "time12 = time.time()\n",
    "print(\"2 trees and interpolation\", time12-time11)\n",
    "print(\"time block 2\", time12-time9)\n",
    "\n",
    "time_end = time.time()\n",
    "print(\"elapsed: \", time_end-time_start)\n",
    "\n",
    "# Pressure\n",
    "# P = (gamma - 1)*density*internal_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_coords[0][:10])\n",
    "print(cell_coords[0][:10])\n",
    "print(density_set[:10])\n",
    "print(dens_interp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "x = rng.random(10) - 0.5\n",
    "y = rng.random(10) - 0.5\n",
    "z = rng.random(10) - 0.5\n",
    "val = np.hypot(x, y)\n",
    "print(val)\n",
    "X = np.linspace(min(x), max(x))\n",
    "Y = np.linspace(min(y), max(y))\n",
    "Z = np.linspace(min(z), max(z))\n",
    "X, Y, Z = np.meshgrid(X, Y, Z)  # 3D grid for interpolation\n",
    "interp = NearestNDInterpolator(list(zip(x, y, z)), val)\n",
    "interp_result = interp(X, Y, Z)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(x, y, z, \"k\", s=val*100, label=\"input point\")\n",
    "ax.legend()\n",
    "#plt.colorbar()\n",
    "#plt.axis(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify NDinterpolator to return KDtree\n",
    "\n",
    "### NOTE - 02/16/22 :: I actually dont think I need to do this, NearestNDinterpolator will generate a tree upon initialization. I can then save the resulting interpolator object and access it.\n",
    "\n",
    "When interpolating data from a nearest-neighbor tree to a set of FLASH block cells, the default scipy.interpolate.NearestNDInterpolator will regenerate the nearest-neighbor KDtree for EACH set of cells AND for each unique field value. This is cumbersome and a waste of time. The Tree generated will not be different for each FLASH block. \n",
    "\n",
    "What I want to do is construct a single KDTree for the entire simulation space for each unique field value. scipy.interpolate.NearestNDInterpolator already does this, but I now need to have the tree passed out as an object so I can save it while I pass in new block location data.\n",
    "\n",
    "Let's first try just copy and pasting the scipy.interpolate.NearestNDInterpolator github source code and modifying that.\n",
    "\n",
    "**MAKE SURE TO CLEAR KERNEL BEFORE RUNNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "class MyClass(object):\n",
    "    def __init__(self):\n",
    "        print(\"never called in this case\")\n",
    "    def __new__(cls):\n",
    "        return 42\n",
    "\n",
    "obj = MyClass()\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.interpolate.interpnd import LinearNDInterpolator, NDInterpolatorBase, \\\n",
    "     CloughTocher2DInterpolator, _ndim_coords_from_arrays\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "__all__ = ['griddata', 'NearestNDInterpolator', 'LinearNDInterpolator',\n",
    "           'CloughTocher2DInterpolator']\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Nearest-neighbor interpolation\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class NearestNDInterpolator(NDInterpolatorBase):\n",
    "    \"\"\"NearestNDInterpolator(x, y).\n",
    "    Nearest-neighbor interpolation in N > 1 dimensions.\n",
    "    .. versionadded:: 0.9\n",
    "    Methods\n",
    "    -------\n",
    "    __call__\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : (Npoints, Ndims) ndarray of floats\n",
    "        Data point coordinates.\n",
    "    y : (Npoints,) ndarray of float or complex\n",
    "        Data values.\n",
    "    rescale : boolean, optional\n",
    "        Rescale points to unit cube before performing interpolation.\n",
    "        This is useful if some of the input dimensions have\n",
    "        incommensurable units and differ by many orders of magnitude.\n",
    "        .. versionadded:: 0.14.0\n",
    "    tree_options : dict, optional\n",
    "        Options passed to the underlying ``cKDTree``.\n",
    "        .. versionadded:: 0.17.0\n",
    "    Notes\n",
    "    -----\n",
    "    Uses ``scipy.spatial.cKDTree``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, y, rescale=False, tree_options=None):\n",
    "        NDInterpolatorBase.__init__(self, x, y, rescale=rescale,\n",
    "                                    need_contiguous=False,\n",
    "                                    need_values=False)\n",
    "        if tree_options is None:\n",
    "            tree_options = dict()\n",
    "        self.tree = cKDTree(self.points, **tree_options)\n",
    "        self.values = np.asarray(y)\n",
    "    def __gettree__(self, *args):\n",
    "        xi = _ndim_coords_from_arrays(args, ndim=self.points.shape[1])\n",
    "    def __call__(self, *args):\n",
    "        \"\"\"\n",
    "        Evaluate interpolator at given points.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1, x2, ... xn: array-like of float\n",
    "            Points where to interpolate data at.\n",
    "            x1, x2, ... xn can be array-like of float with broadcastable shape.\n",
    "            or x1 can be array-like of float with shape ``(..., ndim)``\n",
    "        \"\"\"\n",
    "        xi = _ndim_coords_from_arrays(args, ndim=self.points.shape[1])\n",
    "        xi = self._check_call_shape(xi)\n",
    "        xi = self._scale_x(xi)\n",
    "        dist, i = self.tree.query(xi)\n",
    "        print(dist)\n",
    "        print(i)\n",
    "        return self.tree, self.values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84426697  0.43624385  0.20597949  0.51723864  0.93119179]\n",
      "[9 9 4 1 1]\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('../../AREPO-TORCH/snapshot_550_9.hdf5','r')\n",
    "\n",
    "coords_set = np.array(f[\"PartType0\"][\"Coordinates\"])\n",
    "x = coords_set[:,0]\n",
    "y = coords_set[:,1]\n",
    "z = coords_set[:,2]\n",
    "data_coords = [x,y,z]\n",
    "\n",
    "cellX = np.linspace(min(x), max(x), num=5)\n",
    "cellY = np.linspace(min(y), max(y), num=5)\n",
    "cellZ = np.linspace(min(z), max(z), num=5)\n",
    "cell_coords = [cellX,cellY,cellZ]\n",
    "\n",
    "density_set = np.array(f[\"PartType0\"][\"Density\"])\n",
    "interp = NearestNDInterpolator(list(zip(data_coords[0], data_coords[1], data_coords[2]))[:10], density_set[:10])\n",
    "interp_tree, interp_cells = interp(cell_coords[0], cell_coords[1], cell_coords[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(307.32745726603929, 295.71514332144307, 299.8467853053146), (307.32773065235023, 295.71514483687423, 299.84738598300265), (307.32693167395308, 295.71501957049384, 299.84706370162797), (307.32613496877411, 295.71482830715257, 299.84634964835192), (307.32516232709617, 295.71488384831486, 299.84740941715035), (307.32628622307715, 295.71407493450846, 299.84696945155844), (307.32527589008714, 295.71423313626292, 299.8472064983726), (307.32626185603021, 295.71335614839882, 299.84651446265127), (307.32644820415413, 295.71272268570414, 299.84749067537427), (307.32515601804204, 295.71298357635857, 299.84625435011731)]\n",
      "[ 306.72665051  306.97664902  307.22664753  307.47664603  307.72664454]\n",
      "[ 0.04316753  0.04316753  0.08458693  0.22854971  0.22854971]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(data_coords[0], data_coords[1], data_coords[2]))[:10])\n",
    "print(cell_coords[0])\n",
    "#print(interp_tree.query())\n",
    "print(interp_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Interpolator, save as pickle, access and interpolate.\n",
    "\n",
    "I want to be able to generate a KDtree once, save that tree-object to a pickle, reload the object in a new environment and interpolate from the tree data for random data points without having to reconstruct the tree.\n",
    "\n",
    "scipy.interpolate.NearestNDInterpolator\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.NearestNDInterpolator.html\n",
    "https://github.com/scipy/scipy/blob/v1.7.1/scipy/interpolate/ndgriddata.py#L20-L111\n",
    "Steps:\n",
    "\n",
    "1. Read in AREPO snapshot (~9 million points)\n",
    "2. Use scipy NearestNDInterpolator to construct tree from the AREPO cell centers and assign a set of field values (density, pressure, eint) to the tree leafs. \n",
    "3. Save the \"interpolator\" object a.k.a. the tree to a pickle file.\n",
    "4. Reload the pickle file, interpolate from the tree to a set of random cell centers mimicking a FLASH block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read AREPO Positions: 0.3435380458831787\n",
      "Read field values from AREPO HDF5 & build dataset: 0.9621689319610596\n",
      "Generate tree object from dataset: 18.51636505126953\n",
      "Pickle the tree: 1.7888500690460205\n",
      "Unpickle and unpack the tree: 1.8587477207183838\n",
      "Interpolate field values from tree: 0.029933929443359375\n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import NearestNDInterpolator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import h5py\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "# Read AREPO HDF5 file and extract cell center coordinates\n",
    "f = h5py.File('../../AREPO-TORCH/snapshot_550_9.hdf5','r')\n",
    "coords_set = np.array(f[\"PartType0\"][\"Coordinates\"])\n",
    "x = coords_set[:,0]\n",
    "y = coords_set[:,1]\n",
    "z = coords_set[:,2]\n",
    "data_coords = [x,y,z]\n",
    "\n",
    "time_read_arepo_positions = time.time()\n",
    "\n",
    "# Extract field values from AREPO HDF5\n",
    "density_set = np.array(f[\"PartType0\"][\"Density\"])\n",
    "intEner_set = np.array(f[\"PartType0\"][\"InternalEnergy\"])\n",
    "velocity_set = np.array(f[\"PartType0\"][\"Velocities\"])\n",
    "#We need to separate velocity vector, need to interpolate each component\n",
    "velx = velocity_set[:,0]\n",
    "vely = velocity_set[:,1]\n",
    "velz = velocity_set[:,2]\n",
    "\n",
    "data_set = np.stack((density_set, intEner_set, velx, vely, velz), axis=-1)\n",
    "\n",
    "time_read_field_values = time.time()\n",
    "\n",
    "# Create interpolator object (density tree)\n",
    "data_tree = NearestNDInterpolator(list(zip(data_coords[0], data_coords[1], data_coords[2])), data_set)\n",
    "\n",
    "time_gen_tree_obj = time.time()\n",
    "\n",
    "# Pickling density tree\n",
    "file_w = open('field_tree_obj.pickle', 'wb')\n",
    "pickle.dump(data_tree, file_w)\n",
    "file_w.close()\n",
    "\n",
    "time_dump_pickle = time.time()\n",
    "\n",
    "# Unpickling density tree\n",
    "file_r = open('field_tree_obj.pickle', 'rb')\n",
    "tree_struct = pickle.load(file_r)\n",
    "file_r.close()\n",
    "\n",
    "time_load_pickle = time.time()\n",
    "\n",
    "# Making fake FLASH block\n",
    "#cellX = np.linspace(min(x), max(x), num=4096)\n",
    "#cellY = np.linspace(min(y), max(y), num=4096)\n",
    "#cellZ = np.linspace(min(z), max(z), num=4096)\n",
    "\n",
    "x_ = np.linspace(min(x), max(x), num=16)\n",
    "y_ = np.linspace(min(y), max(y), num=16)\n",
    "z_ = np.linspace(min(z), max(z), num=16)\n",
    "\n",
    "cellX, cellY, cellZ = np.meshgrid(x_, y_, z_, indexing='ij')\n",
    "\n",
    "cell_coords = [cellX,cellY,cellZ]\n",
    "#mesh_grid()\n",
    "\n",
    "time_make_FLASH_cell = time.time()\n",
    "\n",
    "interp_data = tree_struct(cell_coords[0], cell_coords[1], cell_coords[2])\n",
    "\n",
    "time_interp_density = time.time()\n",
    "\n",
    "print(\"Read AREPO Positions:\", time_read_arepo_positions-time_start)\n",
    "print(\"Read field values from AREPO HDF5 & build dataset:\", time_read_field_values-time_read_arepo_positions)\n",
    "print(\"Generate tree object from dataset:\", time_gen_tree_obj-time_read_field_values)\n",
    "print(\"Pickle the tree:\", time_dump_pickle-time_gen_tree_obj)\n",
    "print(\"Unpickle and unpack the tree:\", time_load_pickle-time_dump_pickle)\n",
    "print(\"Interpolate field values from tree:\", time_interp_density-time_make_FLASH_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_array = np.stack((density_set, intEner_set), axis=-1)\n",
    "\n",
    "interp = NearestNDInterpolator(list(zip(data_coords[0], data_coords[1], data_coords[2])), field_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[306.72665051 306.72665051 306.72665051 306.72665051 306.72665051\n",
      " 306.72665051 306.72665051 306.72665051 306.72665051 306.72665051\n",
      " 306.72665051 306.72665051 306.72665051 306.72665051 306.72665051\n",
      " 306.72665051]\n",
      "[[ 1.59712598e-04  2.01250295e+02  1.73493136e+02  1.83889039e+02\n",
      "  -3.09092233e+01]\n",
      " [ 1.54659612e-04  1.98462267e+02  1.80010856e+02  1.85439946e+02\n",
      "  -2.86197465e+01]\n",
      " [ 1.98167498e-04  2.01758205e+02  1.62266705e+02  1.71361752e+02\n",
      "  -2.63176593e+01]\n",
      " [ 1.81317620e-04  1.97931108e+02  1.62177612e+02  1.69600959e+02\n",
      "  -2.10376714e+01]\n",
      " [ 6.33821540e-05  2.51523280e+02  1.82456069e+02  1.71255272e+02\n",
      "  -1.07113098e+01]\n",
      " [ 6.33821540e-05  2.51523280e+02  1.82456069e+02  1.71255272e+02\n",
      "  -1.07113098e+01]\n",
      " [ 3.16759973e-05  3.51497019e+02  2.12673870e+02  1.79019955e+02\n",
      "   1.34268624e+01]\n",
      " [ 3.16759973e-05  3.51497019e+02  2.12673870e+02  1.79019955e+02\n",
      "   1.34268624e+01]\n",
      " [ 1.68996313e-05  5.42887043e+02  2.16485571e+02  1.83798699e+02\n",
      "   2.32342590e+01]\n",
      " [ 1.23307751e-03  1.40705953e+02  1.47676999e+02  1.87303308e+02\n",
      "  -8.30396209e+00]\n",
      " [ 5.36026034e-04  1.63097792e+02  1.60088412e+02  1.87734387e+02\n",
      "   5.50728660e+00]\n",
      " [ 1.19922224e-03  1.39347321e+02  1.77495933e+02  1.91461284e+02\n",
      "   1.37685075e+01]\n",
      " [ 1.21076429e-03  1.39409195e+02  1.77413819e+02  1.91465153e+02\n",
      "   1.37149114e+01]\n",
      " [ 1.93119531e-03  1.27344176e+02  1.74950194e+02  1.94869443e+02\n",
      "   1.10069123e+01]\n",
      " [ 2.42963353e-03  1.22527714e+02  1.85294747e+02  2.00444984e+02\n",
      "   9.46680614e+00]\n",
      " [ 1.22382689e-03  1.37892896e+02  1.81770020e+02  2.04166710e+02\n",
      "   5.61855518e+00]]\n"
     ]
    }
   ],
   "source": [
    "#print(interp(cell_coords[0], cell_coords[1], cell_coords[2]))\n",
    "print(cellX[0][0])\n",
    "print(interp_data[0][0])\n",
    "#print(interp_eint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1,  0],\n",
       "       [ 2, -2, 10],\n",
       "       [ 3, -3, 20],\n",
       "       [ 4, -4, 30],\n",
       "       [ 5, -5, 40]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([-1,-2,-3,-4,-5])\n",
    "c = np.array([0, 10, 20, 30, 40])\n",
    "\n",
    "np.stack((a,b,c),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
